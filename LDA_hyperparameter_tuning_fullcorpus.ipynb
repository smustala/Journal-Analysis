{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA_hyperparameter_tuning_fullcorpus.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68Hk3q5HhIfF"
      },
      "source": [
        "**Tuning for the number of topics and passes**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwNH5gT8Y2mL"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import smart_open\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models import LdaMulticore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poHJuUk4ZE-y",
        "outputId": "de138730-a7d5-4e93-d73a-bb07f23f891a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZYPFKloZG69"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Journal_Analysis/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cli_IA2iZbqx"
      },
      "source": [
        "def extract_documents(folder_name):\n",
        "  import os\n",
        "  docs = []\n",
        "  allfiles = []\n",
        "  for entry in os.scandir(folder_name):\n",
        "      if entry.path.endswith(\".txt\") and entry.is_file():\n",
        "          path_paper = entry.path\n",
        "          allfiles.append(path_paper)\n",
        "          if os.stat(path_paper).st_size == 0:\n",
        "              continue\n",
        "          with open(path_paper) as f:\n",
        "            text = f.read()\n",
        "            docs.append(text)\n",
        "  return docs, allfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVzVPqMDZN5j"
      },
      "source": [
        "docs, allfiles = extract_documents(path + 'allpapersTXT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvRLn6WRauzz",
        "outputId": "c1676e4e-4e4f-480e-e33b-c526a36b8d52"
      },
      "source": [
        "print(len(docs))\n",
        "print(docs[0][:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "226\n",
            "The Artisan and His Audience: Identification with Work and Price Setting in a Handicraft Cluster in Southern India\n",
            "Using ethnographic, experimental, and survey data from a handicraft cluster in southern India, this paper reports on a study of when and why people who identify with their work might sacrifice financial rewards in their economic decisions. Based on findings from ethnographic fieldwork, I hypothesize that the monetary value that individuals who identify with their work seek for their\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "51dbg7dGnUyE",
        "outputId": "e53a5673-edd0-40f6-c769-6a52a4c47d19"
      },
      "source": [
        "allfiles[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Journal_Analysis/allpapersTXT/10.1177_0001839217725782.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkDhWFX9lYjP",
        "outputId": "2a44946f-a2ed-42d0-ee87-2bae7d731bb0"
      },
      "source": [
        "print(docs[0][:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Artisan and His Audience: Identification with Work and Price Setting in a Handicraft Cluster in Southern India\n",
            "Using ethnographic, experimental, and survey data from a handicraft cluster in southern India, this paper reports on a study of when and why people who identify with their work might sacrifice financial rewards in their economic decisions. Based on findings from ethnographic fieldwork, I hypothesize that the monetary value that individuals who identify with their work seek for their\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHwQTmAlbIA3"
      },
      "source": [
        "# Tokenize the documents.\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Split the documents into tokens.\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for idx in range(len(docs)):\n",
        "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
        "    #docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
        "\n",
        "# Remove numbers, but not words that contain numbers.\n",
        "docs = [[token.lower() for token in doc] for doc in docs]\n",
        "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
        "\n",
        "# Remove words that are less than 5 characters.\n",
        "docs = [[token for token in doc if len(token) > 4] for doc in docs]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHw2WRvObrC2",
        "outputId": "13a9e4d9-e5bb-4e35-9a2e-5c54d9fe4d19"
      },
      "source": [
        "# Lemmatize the documents.\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_xhuzRXbsoe",
        "outputId": "e8f14366-71a5-4157-ec73-fedc3e6d3efc"
      },
      "source": [
        "#Filter out stop words\n",
        "nltk.download('stopwords')\n",
        "en_stop = nltk.corpus.stopwords.words('english')\n",
        "print(len(en_stop))\n",
        "en_stop.extend([\"organization\", \"organizational\", \"organizing\", \"would\", \"could\", \"result\", \"study\", \"model\", \"likely\", \"effect\", \"effected\", \"variable\", \"variables\", \"measure\", \"include\", \"suggest\", \"first\", \"level\", \"research\"])\n",
        "print(len(en_stop))\n",
        "\"organization\" in en_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "179\n",
            "198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJGITqv0cR0h"
      },
      "source": [
        "docs = [[token for token in doc if token not in en_stop] for doc in docs]   #remove stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfz6KtAjchGP",
        "outputId": "ec9846ab-2ec5-4e2b-97af-6c4c926d7215"
      },
      "source": [
        "# Compute bigrams.\n",
        "from gensim.models import Phrases\n",
        "\n",
        "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
        "bigram = Phrases(docs, min_count=20)\n",
        "for idx in range(len(docs)):\n",
        "    for token in bigram[docs[idx]]:\n",
        "        if '_' in token:\n",
        "            # Token is a bigram, add to document.\n",
        "            docs[idx].append(token)\n",
        "            #print(\"yes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkmRtGd7cpmn",
        "outputId": "74d0e457-ff0f-4bc2-8727-5a0ee0dba5ca"
      },
      "source": [
        "# Remove rare and common tokens.\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = Dictionary(docs)\n",
        "print(len(dictionary))\n",
        "\n",
        "# Filter out words that occur less than 2 documents, or more than 70% of the documents.\n",
        "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
        "print(len(dictionary))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25096\n",
            "11914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kWWlqGxc-Av"
      },
      "source": [
        "# Bag-of-words representation of the documents.\n",
        "corpus = [dictionary.doc2bow(doc) for doc in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8paIqoJdgTX",
        "outputId": "952c7c99-01a4-4aa0-9fdd-db54eaddfe83"
      },
      "source": [
        "print('Number of unique tokens: %d' % len(dictionary))\n",
        "print('Number of documents: %d' % len(corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique tokens: 11914\n",
            "Number of documents: 226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ehkBSRy6FD"
      },
      "source": [
        "def modify_string(probability_string):\n",
        "  prob = [float(x.split(\"*\")[0]) for x in probability_string.split(\"+\")]\n",
        "  words = [x.split(\"*\")[1] for x in probability_string.split(\"+\")]\n",
        "  return prob,words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8ke6c7ny_md"
      },
      "source": [
        "def make_df(topics):\n",
        "  topic_list = []\n",
        "  df_all = []\n",
        "  for topic in topics:\n",
        "    topic_list.append(\"topic {0}\".format(topic[0]))\n",
        "    prob, words = modify_string(topic[1])\n",
        "    df_topic = pd.DataFrame(data = [prob, words], index = [\"Probabilities\", \"Words\"]).T\n",
        "    df_all.append(df_topic)\n",
        "  df = pd.concat(df_all, axis = 1, keys = topic_list  )   #https://stackoverflow.com/questions/40820017/how-to-create-a-multilevel-dataframe-in-pandas\n",
        "  \n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP8W2vgm20sH"
      },
      "source": [
        "Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZN_p0y23LK0"
      },
      "source": [
        "Parameters to tune: Number of topics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUIonKZ_nx7-"
      },
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, passes, eta, alpha):\n",
        "    from gensim.models import CoherenceModel\n",
        "\n",
        "    lda_model = LdaModel(\n",
        "            corpus= corpus, id2word=dictionary, num_topics= k, \n",
        "            chunksize=2000, eta= eta,\n",
        "            passes= passes, iterations = 400, alpha= alpha, random_state= 42)\n",
        "    \n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts= docs, dictionary=dictionary, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ-hi0YK3fgt",
        "outputId": "89958a38-ddea-4087-b9d5-f160434f1adc"
      },
      "source": [
        "min_topics = 10\n",
        "max_topics = 15\n",
        "step_size = 1\n",
        "topics_range = np.arange(min_topics, max_topics, step_size)\n",
        "print(topics_range)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 11 12 13 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_xBoP4KN42w"
      },
      "source": [
        "Looping over topics\n",
        " <br>eta = \"auto\", alpha = \"auto, passes = 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tIyoIi42XxY",
        "outputId": "73f99189-761c-4be4-8201-b8ed4c3c9ea7"
      },
      "source": [
        "import time\n",
        "t1 = time.time()\n",
        "#Validation set is the whole corpus\n",
        "# Topics range\n",
        "min_topics = 10\n",
        "max_topics = 15\n",
        "step_size = 1\n",
        "topics_range = np.arange(min_topics, max_topics, step_size)\n",
        "\n",
        "#Passes range\n",
        "passes_range = [1000]\n",
        "\n",
        "model_results = {\n",
        "                 'Topics': [],\n",
        "                 'Passes': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "#Looping over parameter ranges \n",
        "for num_topics in topics_range:\n",
        "  for passes in passes_range:\n",
        "    cv = compute_coherence_values(corpus, dictionary, num_topics, passes, \"auto\", \"auto\")\n",
        "    print(num_topics)\n",
        "    print(cv)\n",
        "\n",
        "    # Save the model results\n",
        "    model_results['Topics'].append(num_topics)\n",
        "    model_results['Passes'].append(passes)\n",
        "    model_results['Coherence'].append(cv)\n",
        "    print(\"done with one set of parameters\")\n",
        "#save it as a csv \n",
        "df_tuning = pd.DataFrame(model_results)\n",
        "df_tuning.to_csv(path + 'lda_fullcorpus_tuning_results.csv', index=False)\n",
        "t2 = time.time()\n",
        "print(\"Time elapsed in minutes: {}\".format((t2-t1)/60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "0.3811563177476281\n",
            "done with one set of parameters\n",
            "11\n",
            "0.3742224012177109\n",
            "done with one set of parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "S_f94hmY2Nlw",
        "outputId": "a878b6b7-de48-4f0a-e153-1418120bf552"
      },
      "source": [
        "df_tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5d661b0712cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_tuning' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "TC5XfnJGOota",
        "outputId": "60c02661-08d8-4892-e0f8-49f9f96bf54a"
      },
      "source": [
        "df_tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topics</th>\n",
              "      <th>Passes</th>\n",
              "      <th>Coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>200</td>\n",
              "      <td>0.341962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>500</td>\n",
              "      <td>0.358769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.360546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>200</td>\n",
              "      <td>0.325037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>500</td>\n",
              "      <td>0.343494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.352838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12</td>\n",
              "      <td>200</td>\n",
              "      <td>0.338209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>500</td>\n",
              "      <td>0.346423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.347784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13</td>\n",
              "      <td>200</td>\n",
              "      <td>0.348951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>13</td>\n",
              "      <td>500</td>\n",
              "      <td>0.371548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>13</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.374224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>14</td>\n",
              "      <td>200</td>\n",
              "      <td>0.354513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>500</td>\n",
              "      <td>0.372573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Topics  Passes  Coherence\n",
              "0       10     200   0.341962\n",
              "1       10     500   0.358769\n",
              "2       10    1000   0.360546\n",
              "3       11     200   0.325037\n",
              "4       11     500   0.343494\n",
              "5       11    1000   0.352838\n",
              "6       12     200   0.338209\n",
              "7       12     500   0.346423\n",
              "8       12    1000   0.347784\n",
              "9       13     200   0.348951\n",
              "10      13     500   0.371548\n",
              "11      13    1000   0.374224\n",
              "12      14     200   0.354513\n",
              "13      14     500   0.372573\n",
              "14      14    1000   0.377603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKviFKtTdGNe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}